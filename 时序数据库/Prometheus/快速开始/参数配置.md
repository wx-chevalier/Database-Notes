# Prometheus 参数配置

Prometheus 配置方式有两种：命令行，用来配置不可变命令参数，主要是 Prometheus 运行参数，比如数据存储位置、配置文件，用来配置 Prometheus 应用参数，比如数据采集，报警对接。不重启进程配置生效方式也有两种：

- 对进程发送信号 SIGHUP，`kill -HUP <pid>`。
- HTTP POST 请求，需要开启--web.enable-lifecycle 选项 `curl -X POST http://192.168.66.112:9091/-/reload`。

# 命令行配置

## 存储

Prometheus 具有几个允许配置本地存储的标志。最重要的是：

- --storage.tsdb.path: 文件的存储位置，默认是 data/.=。

- --storage.tsdb.retention.time: 这确定了何时删除旧数据。默认为 15d。如果此标志设置为默认值以外的其他值，则覆盖 storage.tsdb.retention。

- --storage.tsdb.retention.size: [EXPERIMENTAL] 这确定了存储块可以使用的最大字节数（请注意，这不包括 WAL 大小，这可能是很大的）。最旧的数据将首先被删除。默认为 0 或禁用。该标志是实验性的，可以在将来的版本中进行更改。支持的单位：KB，MB，GB，PB。例如：512MB。

- --storage.tsdb.wal-compression: 此标志启用预写日志（WAL）的压缩。根据您的数据，您可以预期 WAL 大小将减少一半，而额外的 CPU 负载却很少。请注意，如果启用此标志，然后将 Prometheus 降级到 2.11.0 以下的版本，则您将需要删除 WAL，因为它将不可读。

# 配置文件基础

我们可以通过参数 --config.file 来指定配置文件，配置文件格式为 YAML。配置文件的基础构成如下：

```yml
＃全局配置
global:

＃规则配置主要是配置报警规则
rule_files:

＃抓取配置，主要配置抓取客户端相关
scrape_configs:

＃报警配置
alerting:

＃用于远程存储写配置
remote_write:

＃用于远程读配置
remote_read:
```

配置文件中通用字段值格式：`<boolean>`: 布尔类型值为 true 和 false、`<scheme>`: 协议方式包含 http 和 https。我们可以打开默认的配置文件 prometheus.yml 看下里面的内容：

```yaml
/etc/prometheus $ cat prometheus.yml
# my global config
global:
  scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
  # scrape_timeout is set to the global default (10s).

# Alertmanager configuration
alerting:
  alertmanagers:
  - static_configs:
    - targets:
      # - alertmanager:9093

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: 'prometheus'

    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.

    static_configs:
    - targets: ['localhost:9090']
```

Prometheus 默认的配置文件分为四大块：

- global 块：Prometheus 的全局配置，比如 scrape_interval 表示 Prometheus 多久抓取一次数据，evaluation_interval 表示多久检测一次告警规则。

- alerting 块：关于 Alertmanager 的配置。

- rule_files 块：告警规则。

- scrape_config 块：这里定义了 Prometheus 要抓取的目标，我们可以看到默认已经配置了一个名称为 prometheus 的 job，这是因为 Prometheus 在启动的时候也会通过 HTTP 接口暴露自身的指标数据，这就相当于 Prometheus 自己监控自己，虽然这在真正使用 Prometheus 时没啥用处，但是我们可以通过这个例子来学习如何使用 Prometheus；可以访问 http://localhost:9090/metrics 查看 Prometheus 暴露了哪些指标。

# global 字段

```sh
# scrape_interval，全局默认的数据拉取间隔
[ scrape_interval: <duration> | default = 1m ]

# scrape_timeout，全局默认的单次数据拉取超时，当报context deadline exceeded错误时需要在特定的job下配置该字段
[ scrape_timeout: <duration> | default = 10s ]

# evaluation_interval，全局默认的规则(主要是报警规则)拉取间隔
[ evaluation_interval: <duration> | default = 1m ]

# external_labels，该服务端在与其他系统对接所携带的标签
[ <labelname>: <labelvalue> ... ]
```

# rule_files

Prometheus 支持两种类型的规则：记录规则和警报规则。要在 Prometheus 中包含规则，请创建一个包含必要规则语句的文件，并让 Prometheus 通过配置中的 rule_files 字段加载规则文件。

## 规则分组 rule_group

不论是 recording rules 还是 alerting rules 都要在组里面：

```yml
groups:
  #groups的名称
  - name: example
    #该组下的规则
    rules: [- <rule> ...]
```

## 定义 Recording rules

有一些监控的数据查询时很耗时的，还有一些数据查询所使用的查询语句很繁琐。Recording rules 可以把一些很耗时的查询或者很繁琐的查询进行提前查询好，然后在需要数据的时候就可以很快拉出数据。

```yml
# 指出规则类型record 后面接名称
record: <string>

# 写入PromQL表达式查询语句
#expr: sum(http_inprogress_requests) by (job)
expr: <string>

# 在存储数据之前加上标签
labels: [<labelname>: <labelvalue>]

groups:
  - name: example
    rules:
      - record: job:http_inprogress_requests:sum
        expr: sum(http_inprogress_requests) by (job)
```

## 规则检查

```sh
#打镜像后使用
FROM golang:1.10

RUN GOOS=linux GOARCH=amd64 CGO_ENABLED=0 go get -u github.com/prometheus/prometheus/cmd/promtool

FROM alpine:latest

COPY --from=0 /go/bin/promtool /bin
ENTRYPOINT ["/bin/promtool"]

# 编译
docker build -t promtool:0.1 .
#使用
docker run --rm -v /root/test/prom:/opt promtool:0.1 check rules /opt/rule.yml
#返回
Checking /opt/rule.yml
  SUCCESS: 1 rules found
```

# scrape_configs

拉取数据配置，在配置字段内可以配置拉取数据的对象(Targets)，job 以及实例。

## job_name

定义 job 名称，是一个拉取单元。每个 job_name 都会自动引入默认配置如：

- scrape_interval 依赖全局配置
- scrape_timeout 依赖全局配置
- metrics_path 默认为’/metrics’
- scheme 默认为’http’

这些也可以在单独的 job 中自定义：

```yml
[ scrape_interval: <duration> | default = <global_config.scrape_interval> ]
[ scrape_timeout: <duration> | default = <global_config.scrape_timeout> ]
[ metrics_path: <path> | default = /metrics ]
```

## honor_labels

服务端拉取过来的数据也会存在标签，配置文件中也会有标签，这样就可能发生冲突：

- true 就是以抓取数据中的标签为准
- false 就会重新命名抓取数据中的标签为“exported”形式，然后添加配置文件中的标签

```sh
[ honor_labels: <boolean> | default = false ]
```

## scheme

切换抓取数据所用的协议

```sh
[ scheme: <scheme> | default = http ]
```

## params

定义可选的 url 参数：

```sh
[ <string>: [<string>, ...] ]
```

# 抓取认证类

每次抓取数据请求的认证信息。

## basic_auth

password 和 password_file 互斥只可以选择其一：

```sh
basic_auth:
  [ username: <string> ]
  [ password: <secret> ]
  [ password_file: <string> ]
```

## bearer_token

bearer_token 和 bearer_token_file 互斥只可以选择其一：

```sh
[ bearer_token: <secret> ]
[ bearer_token_file: /path/to/bearer/token/file ]
```

## tls_config

抓取 ssl 请求时证书配置：

```sh
tls_config:
  [ ca_file: <filename> ]
  [ cert_file: <filename> ]
  [ key_file: <filename> ]
  [ server_name: <string> ]
  #禁用证书验证
  [ insecure_skip_verify: <boolean> ]
```

## proxy_url

通过代理去主去数据

```sh
[ proxy_url: <string> ]
```

# 服务发现类

Prometheus 支持多种服务现工具，详细配置这里不再展开：

```yml
#sd就是service discovery的缩写
azure_sd_configs:
consul_sd_configs:
dns_sd_configs:
ec2_sd_configs:
openstack_sd_configs:
file_sd_configs:
gce_sd_configs:
kubernetes_sd_configs:
marathon_sd_configs:
nerve_sd_configs:
serverset_sd_configs:
triton_sd_configs:
```

## static_configs

服务发现来获取抓取目标为动态配置，这个配置项目为静态配置，静态配置为典型的 targets 配置，在改配置字段可以直接添加标签：

```yml
- targets: [- '<host>']
  labels: [<labelname>: <labelvalue> ...]
```

采集器所采集的数据都会带有 label，当使用服务发现时，比如 consul 所携带的 label 如下：

```yml
__meta_consul_address: consul地址
__meta_consul_dc: consul中服务所在的数据中心
__meta_consul_metadata_: 服务的metadata
__meta_consul_node: 服务所在consul节点的信息
__meta_consul_service_address: 服务访问地址
__meta_consul_service_id: 服务ID
__meta_consul_service_port: 服务端口
__meta_consul_service: 服务名称
__meta_consul_tags: 服务包含的标签信息
```

这些 label 是数据筛选与聚合计算的基础。

# 数据过滤类

抓取数据很繁杂，尤其是通过服务发现添加的 target。所以过滤就显得尤为重要，我们知道抓取数据就是抓取 target 的一些列 metrics，Prometheus 过滤是通过对标签操作操现的，在字段 relabel_configs 和 metric_relabel_configs 里面配置，两者的配置都需要 relabel_config 字段。该字段需要配置项如下：

```yml
[ source_labels: '[' <labelname> [, ...] ']' ]

[ separator: <string> | default = ; ]

[ target_label: <labelname> ]

[ regex: <regex> | default = (.*) ]

[ modulus: <uint64> ]

[ replacement: <string> | default = $1 ]

#action除了默认动作还有keep、drop、hashmod、labelmap、labeldrop、labelkeep
[ action: <relabel_action> | default = replace ]
```

## target 配置示例

```yml
relabel_configs:
  - source_labels: [job]
    regex: (.*)some-[regex]
    action: drop
  - source_labels: [__address__]
    modulus: 8
    target_label: __tmp_hash
    action: hashmod
```

## target 中 metric 示例

```yml
- job_name: cadvisor
  ...
  metric_relabel_configs:
  - source_labels: [id]
    regex: '/system.slice/var-lib-docker-containers.*-shm.mount'
    action: drop
  - source_labels: [container_label_JenkinsId]
    regex: '.+'
    action: drop
```

# alerting 字段

该字段配置与 Alertmanager 进行对接的配置。

## alert_relabel_configs

此项配置和 scrape_configs 字段中 relabel_configs 配置一样，用于对需要报警的数据进行过滤后发向 Alertmanager。

## alertmanagers

该项目主要用来配置不同的 alertmanagers 服务，以及 Prometheus 服务和他们的链接参数。alertmanagers 服务可以静态配置也可以使用服务发现配置。Prometheus 以 pushing 的方式向 alertmanager 传递数据。

alertmanager 服务配置和 target 配置一样，可用字段如下：

```yml
[ timeout: <duration> | default = 10s ]
[ path_prefix: <path> | default = / ]
[ scheme: <scheme> | default = http ]
basic_auth:
  [ username: <string> ]
  [ password: <string> ]
  [ password_file: <string> ]
[ bearer_token: <string> ]
[ bearer_token_file: /path/to/bearer/token/file ]
tls_config:
  [ <tls_config> ]
[ proxy_url: <string> ]
azure_sd_configs:
  [ - <azure_sd_config> ... ]
consul_sd_configs:
  [ - <consul_sd_config> ... ]
dns_sd_configs:
  [ - <dns_sd_config> ... ]
ec2_sd_configs:
  [ - <ec2_sd_config> ... ]
file_sd_configs:
  [ - <file_sd_config> ... ]
gce_sd_configs:
  [ - <gce_sd_config> ... ]
kubernetes_sd_configs:
  [ - <kubernetes_sd_config> ... ]
marathon_sd_configs:
  [ - <marathon_sd_config> ... ]
nerve_sd_configs:
  [ - <nerve_sd_config> ... ]
serverset_sd_configs:
  [ - <serverset_sd_config> ... ]
triton_sd_configs:
  [ - <triton_sd_config> ... ]
static_configs:
  [ - <static_config> ... ]
relabel_configs:
  [ - <relabel_config> ... ]
```

# 远程读写

Prometheus 可以进行远程读/写数据。字段 remote_read 和 remote_write。

## remote_read

```yml
#远程读取的url
url: <string>

#通过标签来过滤读取的数据
required_matchers:
  [ <labelname>: <labelvalue> ... ]

[ remote_timeout: <duration> | default = 1m ]

#当远端不是存储的时候激活该项
[ read_recent: <boolean> | default = false ]

basic_auth:
  [ username: <string> ]
  [ password: <string> ]
  [ password_file: <string> ]
[ bearer_token: <string> ]
[ bearer_token_file: /path/to/bearer/token/file ]
tls_config:
  [ <tls_config> ]
[ proxy_url: <string> ]
```

## remote_write

```yml
url: <string>

[ remote_timeout: <duration> | default = 30s ]

#写入数据时候进行标签过滤
write_relabel_configs:
  [ - <relabel_config> ... ]

basic_auth:
  [ username: <string> ]
  [ password: <string> ]
  [ password_file: <string> ]

[ bearer_token: <string> ]

[ bearer_token_file: /path/to/bearer/token/file ]

tls_config:
  [ <tls_config> ]

[ proxy_url: <string> ]

#远端写细粒度配置，这里暂时仅仅列出官方注释
queue_config:
  # Number of samples to buffer per shard before we start dropping them.
  [ capacity: <int> | default = 10000 ]
  # Maximum number of shards, i.e. amount of concurrency.
  [ max_shards: <int> | default = 1000 ]
  # Maximum number of samples per send.
  [ max_samples_per_send: <int> | default = 100]
  # Maximum time a sample will wait in buffer.
  [ batch_send_deadline: <duration> | default = 5s ]
  # Maximum number of times to retry a batch on recoverable errors.
  [ max_retries: <int> | default = 3 ]
  # Initial retry delay. Gets doubled for every retry.
  [ min_backoff: <duration> | default = 30ms ]
  # Maximum retry delay.
  [ max_backoff: <duration> | default = 100ms ]
```
